{
  "3": {
    "inputs": {
      "seed": 0,
      "steps": 25,
      "cfg": 5.4,
      "sampler_name": "dpmpp_2m_sde_gpu",
      "scheduler": "exponential",
      "denoise": 0.9,
      "model": [
        "87",
        0
      ],
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "5",
        0
      ]
    },
    "class_type": "KSampler"
  },
  "4": {
    "inputs": {
      "ckpt_name": "analogMadness_v60.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "5": {
    "inputs": {
      "width": [
        "95",
        0
      ],
      "height": [
        "95",
        1
      ],
      "batch_size": 16
    },
    "class_type": "EmptyLatentImage"
  },
  "6": {
    "inputs": {
      "text": "",
      "clip": [
        "96",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "7": {
    "inputs": {
      "text": "",
      "clip": [
        "96",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "11",
        0
      ]
    },
    "class_type": "VAEDecode"
  },
  "11": {
    "inputs": {
      "vae_name": "vae-ft-mse-840000-ema-pruned.ckpt"
    },
    "class_type": "VAELoader"
  },
  "30": {
    "inputs": {
      "frame_rate": 8,
      "loop_count": 0,
      "filename_prefix": "AnimateDiff",
      "format": "video/h264-mp4",
      "pingpong": false,
      "save_image": true,
      "crf": 20,
      "save_metadata": true,
      "audio_file": "",
      "videopreview": {
        "hidden": false,
        "paused": false,
        "params": {
          "filename": "AnimateDiff_00118.mp4",
          "subfolder": "",
          "type": "output",
          "format": "video/h264-mp4"
        }
      },
      "images": [
        "8",
        0
      ]
    },
    "class_type": "VHS_VideoCombine"
  },
  "50": {
    "inputs": {
      "model_name": "improvedHumansMotion_refinedHumanMovement.ckpt",
      "beta_schedule": "sqrt_linear (AnimateDiff)",
      "motion_scale": 1,
      "apply_v2_models_properly": true,
      "model": [
        "96",
        0
      ]
    },
    "class_type": "ADE_AnimateDiffLoaderWithContext"
  },
  "70": {
    "inputs": {
      "weight": 0.55,
      "noise": 0.3,
      "weight_type": "original",
      "start_at": 0,
      "end_at": 0.988,
      "unfold_batch": true,
      "ipadapter": [
        "71",
        0
      ],
      "clip_vision": [
        "72",
        0
      ],
      "image": [
        "81",
        0
      ],
      "model": [
        "50",
        0
      ]
    },
    "class_type": "IPAdapterApply"
  },
  "71": {
    "inputs": {
      "ipadapter_file": "ip-adapter-plus_sd15.safetensors"
    },
    "class_type": "IPAdapterModelLoader"
  },
  "72": {
    "inputs": {
      "clip_name": "IPAdapter_image_encoder_sd15.safetensors"
    },
    "class_type": "CLIPVisionLoader"
  },
  "73": {
    "inputs": {
      "image": "",
      "upload": "image"
    },
    "class_type": "LoadImage"
  },
  "74": {
    "inputs": {
      "amount": 8,
      "image": [
        "73",
        0
      ]
    },
    "class_type": "RepeatImageBatch"
  },
  "75": {
    "inputs": {
      "image": "",
      "upload": "image"
    },
    "class_type": "LoadImage"
  },
  "76": {
    "inputs": {
      "amount": 8,
      "image": [
        "75",
        0
      ]
    },
    "class_type": "RepeatImageBatch"
  },
  "81": {
    "inputs": {
      "image1": [
        "74",
        0
      ],
      "image2": [
        "76",
        0
      ]
    },
    "class_type": "ImageBatch"
  },
  "86": {
    "inputs": {
      "b1": 1.2,
      "b2": 1.3,
      "s1": 0.9,
      "s2": 0.5,
      "model": [
        "70",
        0
      ]
    },
    "class_type": "FreeU_V2"
  },
  "87": {
    "inputs": {
      "multiplier": 0.7,
      "model": [
        "86",
        0
      ]
    },
    "class_type": "RescaleCFG"
  },
  "94": {
    "inputs": {
      "side_length": 768,
      "side": "Longest",
      "upscale_method": "nearest-exact",
      "crop": "disabled",
      "image": [
        "73",
        0
      ]
    },
    "class_type": "Image scale to side"
  },
  "95": {
    "inputs": {
      "image": [
        "94",
        0
      ]
    },
    "class_type": "Get Image Size"
  },
  "96": {
    "inputs": {
      "lora_name": "add_detail.safetensors",
      "strength_model": 0.8,
      "strength_clip": 0.8,
      "model": [
        "4",
        0
      ],
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "LoraLoader"
  }
}
